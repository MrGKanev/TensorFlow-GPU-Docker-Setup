# Use the official TensorFlow GPU image with a specific version 
FROM tensorflow/tensorflow:2.11.0-gpu

# Set image metadata
LABEL name="tensorflow-gpu-custom"
LABEL maintainer="mail@gkanev.com"
LABEL version="1.0"
LABEL description="TensorFlow GPU image with additional tools for ML"

# Set a working directory
WORKDIR /app

# Install system dependencies and clean up in the same layer
RUN apt-get update && apt-get install -y --no-install-recommends \
    wget \
    curl \
    git \
    build-essential \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip and install required Python packages in a single layer
# This creates fewer layers and allows better cleanup
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir \
    numpy \
    pandas \
    scikit-learn \
    matplotlib \
    && find /usr/local/lib/python3.* -name __pycache__ -type d -exec rm -rf {} +

# Add CUDA Path environment variables
ENV PATH="/usr/local/cuda/bin:${PATH}"
ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64:${LD_LIBRARY_PATH}"

# Copy test scripts
COPY test_gpu.py /app/test_gpu.py
COPY tensorflow_pycharm_fix.py /app/tensorflow_pycharm_fix.py
COPY tf_benchmark.py /app/tf_benchmark.py
RUN chmod +x /app/tf_benchmark.py
RUN chmod +x /app/test_gpu.py
RUN chmod +x /app/tensorflow_pycharm_fix.py


# Verify TensorFlow can use the GPU
RUN echo "Note: GPU checks in build will likely fail. The container must be run with --gpus all"

# Final cleanup to reduce image size
RUN apt-get autoremove -y && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    rm -rf /root/.cache && \
    rm -rf /tmp/* && \
    find /usr/local/lib/python3.* -name '*.pyc' -delete && \
    find /usr/local/lib/python3.* -name '*.so' -exec strip -s {} \; || true

# Add a helpful message when container starts
RUN echo '#!/bin/bash' > /entrypoint.sh && \
    echo 'echo "====================================================="' >> /entrypoint.sh && \
    echo 'echo "TensorFlow GPU Container"' >> /entrypoint.sh && \
    echo 'echo "====================================================="' >> /entrypoint.sh && \
    echo 'echo "To verify GPU access, run: python /app/check_gpu.py"' >> /entrypoint.sh && \
    echo 'echo "If no GPU is detected, ensure you:"' >> /entrypoint.sh && \
    echo 'echo "1. Have NVIDIA drivers installed on the host"' >> /entrypoint.sh && \
    echo 'echo "2. Installed nvidia-container-toolkit on the host"' >> /entrypoint.sh && \
    echo 'echo "3. Started the container with: --gpus all flag"' >> /entrypoint.sh && \
    echo 'echo "====================================================="' >> /entrypoint.sh && \
    echo 'exec "$@"' >> /entrypoint.sh && \
    chmod +x /entrypoint.sh

ENTRYPOINT ["/entrypoint.sh"]
CMD ["bash"]
